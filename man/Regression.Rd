% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/regression.R
\name{Regression}
\alias{Regression}
\title{Generalized Regression Outputs}
\usage{
Regression(
  formula = as.formula(NULL),
  data = NULL,
  subset = NULL,
  weights = NULL,
  missing = "Exclude cases with missing data",
  type = "Linear",
  robust.se = FALSE,
  method = "default",
  output = "Coefficients",
  detail = FALSE,
  m = 10,
  seed = 12321,
  statistical.assumptions,
  auxiliary.data = NULL,
  show.labels = FALSE,
  internal = FALSE,
  contrasts = c("contr.treatment", "contr.treatment"),
  relative.importance = FALSE,
  importance.absolute = FALSE,
  interaction = NULL,
  correction = "None",
  interaction.formula = NULL,
  recursive.call = FALSE,
  effects.format = list(max.label = 10),
  outlier.prop.to.remove = NULL,
  stacked.data.check = FALSE,
  unstacked.data = NULL,
  ...
)
}
\arguments{
\item{formula}{An object of class \code{\link{formula}} (or one that can be
coerced to that class): a symbolic description of the model to be fitted.
The details of type specification are given under \sQuote{Details}.}

\item{data}{A \code{\link{data.frame}}.}

\item{subset}{An optional vector specifying a subset of observations to be
used in the fitting process, or, the name of a variable in \code{data}. It
may not be an expression. \code{subset} may not}

\item{weights}{An optional vector of sampling weights, or, the name or, the
name of a variable in \code{data}. It may not be an expression.}

\item{missing}{How missing data is to be treated in the regression. Options:
\code{"Error if missing data"},
\code{"Exclude cases with missing data"},
\code{"Use partial data (pairwise correlations)"},
\code{"Dummy variable adjustment"},
\code{"Imputation (replace missing values with estimates)"}, and
\code{"Multiple imputation"}.}

\item{type}{Defaults to \code{"Linear"}. Other types are: \code{"Poisson"},
\code{"Quasi-Poisson"}, \code{"Binary Logit"}, \code{"NBD"},
\code{"Ordered Logit"}, and \code{"Multinomial Logit"}}

\item{robust.se}{If \code{TRUE}, computes standard errors that are robust to violations of
the assumption of constant variance for linear models, using the HC3 modification of White's (1980) estimator
(Long and Ervin, 2000). This parameter is ignored if weights are applied (as weights already
employ a sandwich estimator). Other options are \code{FALSE} and \code{"FALSE"No}, which do the same
thing, and \code{"hc0"}, \code{"hc1"}, \code{"hc2"}, \code{"hc4"}.}

\item{method}{The method to be used; for fitting. This will only do something if
method = "model.frame", which returns the model frame.}

\item{output}{\code{"Coefficients"} returns a table of coefficients and various
summary and model statistics. It is the default.
\code{"ANOVA"} returns an ANOVA table.
\code{"Detail"} returns a more traditional R output.
\code{"Relative Importance Analysis"} returns a table with Relative Importance scores.
\code{"Shapley Regression"} returns a table with Shapley Importance scores.
\code{"Effects Plot"} returns the effects plot per predictor.}

\item{detail}{This is a deprecated function. If \code{TRUE}, \code{output} is set to \code{R}.}

\item{m}{The number of imputed samples, if using multiple imputation.}

\item{seed}{The random number seed used in imputation and residual computations.}

\item{statistical.assumptions}{A Statistical Assumptions object.}

\item{auxiliary.data}{A \code{\link{data.frame}} containing additional variables
to be used in imputation (if required). While adding more variables will improve
the quality of the imputation, it will dramatically slow down the time to estimate.
Factors and Character variables with a large number of categories should not be included,
as they will both slow down the data and are unlikely to be useful}

\item{show.labels}{Shows the variable labels, as opposed to the names, in the outputs, where a
variables label is an attribute (e.g., attr(foo, "label")).}

\item{internal}{If \code{TRUE}, skips most of the tidying at the end. Only for use when it is
desired to call a relatively light version of Regression for other purposes (e.g., in ANOVA).
This leads to creation of an object of class \code{FitRegression}.)}

\item{contrasts}{A vector of the contrasts to be used for \code{\link{factor}} and
\code{\link{ordered}} variables. Defaults to \code{c("contr.treatment", "contr.treatment"))}.
Set to \code{c("contr.treatment", "contr.poly"))} to use orthogonal polynomials for \code{\link{factor}}
See \code{\link{contrasts}} for more information.}

\item{relative.importance}{Deprecated. To run Relative Importance Analysis, use the output variable.}

\item{importance.absolute}{Whether the absolute value of the relative importance should be shown.}

\item{interaction}{Optional variable to test for interaction with other variables in the model. Output will be a crosstab showing coefficients from both both models.}

\item{correction}{Method to correct for multiple comparisons. Can be one of \code{"None"},
\code{"False Discovery Rate", "Benjamini & Yekutieli", "Bonferroni", "Hochberg", "Holm"} or \code{"Hommel"}.}

\item{interaction.formula}{Used internally for multiple imputation.}

\item{recursive.call}{Used internally to indicate if call is a result of recursion (e.g., multiple imputation).}

\item{effects.format}{A list of items \code{max.label} (the maximum length of a factor label on the x-axis)
and \code{y.title} (the title of the y-axis, defaults to outcome label).}

\item{outlier.prop.to.remove}{A single numeric value that determines the percentage of data points to remove from the
analysis. The data points removed correspond to those in the proportion with the largest residuals.
A value of 0 or NULL would denote no points are removed. A value x, with 0 < x < 0.5 (not inclusive) would
denote that a percentage between none and 50\% of the data points are removed.}

\item{stacked.data.check}{Logical value to determine if the Regression should be the data and formula based off
the \code{unstacked.data} argument by stacking the input and creating a formula based off attributes and provided
labels in the data. More details are given in the argument details for \code{unstacked.data}}

\item{unstacked.data}{A list with two elements that provide the Outcome and Predictors respectively for data that
needs to be stacked. In particular, this is designed to work with input that is created with Q or Displayr which
creates \code{data.frame}s with a particular structure. In particular, the list has two elements, \itemize{
\item \code{Y} A \code{data.frame} with \code{m} columns that represent the \code{m} variables to be stacked.
This \code{data.frame} can also contain an optional 'question' attribute to denote the overall name of this
set variable
\item \code{X} A \code{data.frame} where each column represents a column of a design matrix relevant to one of the
\code{m} variables given in element \code{Y} above. So if the overall regression model has \code{p} predictors.
Then this \code{data.frame} should contain \code{m * p} columns. The naming structure each column is comma
separated of the form 'predictor, outcome' where 'predictor' denotes the predictor name in the regression design
matrix and 'outcome' denotes the name of the variable in element \code{Y}. This format is required to ensure that
the columns are appropriately matched and stacked. The function also accepts column names of the reverse order
with 'outcome, predictor', so long as there isn't any ambiguity.}}

\item{...}{Additional argments to be passed to  \code{\link{lm}} or, if the
data is weighted,  \code{\link[survey]{svyglm}} or \code{\link[survey]{svyolr}}.}
}
\description{
Computes output for seven different regression types.
Those being linear, binary logistic, ordered logistic, binomial, poisson, quasi-poisson and
multinomial. Output includes general coefficient estimates and importance analysis estimates
with possibilities for handling missing data and interaction terms.
}
\details{
In the case of Ordered Logistic regression, this function computes a proporional odds model using
 the cumulative link (logistic). In the case of no weights, the \code{\link[MASS]{polr}} function is used.
 In the case of a weighted regresion, the \code{\link[survey]{svyolr}} function is used.

 "Imputation (replace missing values with estimates)". All selected
 outcome and predictor variables are included in the imputation, along with
 all \code{auxiliary.data}, excluding cases that are excluded via subset or
 have invalid weights, but including cases with missing values of the outcome variable.
 Then, cases with missing values in the outcome variable are excluded from
 the analysis (von Hippel 2007). See \code{\link[flipImputation]{Imputation}}.

 Outlier removal is performed by computing residuals for the regression model and removing the largest residuals
 from the dataset (outlier removal). The model is then refit on the reduced dataset after outliers are removed.
 The residuals used in this process depend on the regression type. For a regression with a numeric response
 (\code{type} is "Linear", "Poisson", "Quasi-Poisson" or  "NBD") in an unweighted regression, the studentised
 deviance residuals are used (see Davison and Snell (1991) and \code{\link[stats]{rstudent}}). In the weighted case
 of the numeric response, the Pearson residuals are used (see Davison and Snell (1991) and
 \code{\link[stats]{residuals.glm}}). In the case of Binary and Ordinal data for both the unweighted and weighted
 regression cases, the Surrogate residuals (SURE) are used (via the implementation in Greenwell, McCarthy and
 Boehmke (2017) with their sure R package). This was based on the recent theoretical paper in Liu and Zhang (2018).
 Currently "Multinomial Logit" is unsupported for automated outlier removal. Possible surrogate residual to be used
 in a future version.
}
\references{
Davison, A. C. and Snell, E. J. (1991) Residuals and diagnostics. In: Statistical Theory and Modelling.
  In Honour of Sir David Cox, FRS, eds. Hinkley, D. V., Reid, N. and Snell, E. J., Chapman & Hall.

  Greenwell, B., McCarthy, A. and Boehmke, B. (2017). sure: Surrogate Residuals for Ordinal and General
  Regression Models. R package version 0.2.0. https://CRAN.R-project.org/package=sure

  von Hippel, Paul T. 2007. "Regression With Missing Y's: An
  Improved Strategy for Analyzing Multiply Imputed Data." Sociological
  Methodology 37:83-117.

  Long, J. S. and Ervin, L. H. (2000). Using heteroscedasticity consistent
  standard errors in the linear regression  model. The American Statistician, 54(3): 217-224.

  Lui, D. and Zhang, H. (2018). Residuals and Diagnostics for Ordinal Regression Models: A Surrogate Approach.
  Journal of the American Statistical Association, 113:522, 845-854.

  Lumley, T. (2004) Analysis of complex survey samples. Journal of Statistical Software 9(1): 1-19

  White, H. (1980), A heteroskedastic-consistent  covariance matrix estimator
  and a direct test of heteroskedasticity. Econometrica, 48, 817-838.
}
